{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edasmalchi/anaconda3/envs/pd1/lib/python3.8/site-packages/fastparquet/dataframe.py:5: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import CategoricalIndex, RangeIndex, Index, MultiIndex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "import sys\n",
    "import operator\n",
    "\n",
    "import fastparquet\n",
    "import snappy\n",
    "\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldays = pd.read_csv('VehtoSep11new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showall(df):\n",
    "    #shows entire dataframe\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def zeropad_dates(str_date):\n",
    "    \"\"\"pads month and day with zeroes\"\"\"\n",
    "    padded_date = ''\n",
    "    split_date = str_date.split('/')\n",
    "    for value in split_date:\n",
    "        if len(value) < 2:\n",
    "            value = '0' + value\n",
    "        padded_date += (value + '/')\n",
    "    padded_date = padded_date[:-1]\n",
    "    return padded_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_violator(row, st_time='18:00:00', end_time='22:00:00', legal_minutes=15):\n",
    "    ##TODO speedup candidate?\n",
    "    ##TODO rewrite cleaner?\n",
    "    \"\"\"classify a row as a violator or not\n",
    "    considers +15min parked from 18:00-22:30 a violation\n",
    "    \"\"\"\n",
    "    begin, end = row['Begin Date'] + row['Begin Time'], row['Begin Date'] + row['End Time']\n",
    "    time_parked = {'Start':datetime_from_str(begin), 'End':datetime_from_str(end)}\n",
    "    datestr = begin[:10]\n",
    "    \n",
    "    enf_start = datestr + st_time\n",
    "    enf_end = datestr + end_time\n",
    "    enforcement_times = {'Start':datetime_from_str(enf_start), 'End':datetime_from_str(enf_end)}\n",
    "    \n",
    "    latest_start = max(time_parked['Start'], enforcement_times['Start'])\n",
    "    earliest_end = min(time_parked['End'], enforcement_times['End'])\n",
    "    delta = (earliest_end - latest_start).seconds\n",
    "    \n",
    "    suffix = ''\n",
    "    if row['CNS?']:\n",
    "        suffix = ', CNS'\n",
    "    elif row['TNC?']:\n",
    "        suffix = ', TNC'\n",
    "    \n",
    "    #maximum parking duration during enforcement interval\n",
    "    legal_duration_seconds = legal_minutes * 60\n",
    "    #hardcoded 3-hr limit for space 3\n",
    "    legal_duration_spc3 = 180 * 60\n",
    "    max_observation = 60**2 * 11\n",
    "    #Space 3 not part of loading zone, so vehicles there aren't violators\n",
    "    if (delta > legal_duration_seconds and delta < max_observation and\n",
    "                    row['Vehicle Location'] in ['Space 1', 'Space 2']):\n",
    "        return 'Violator' + suffix\n",
    "    elif (delta > legal_duration_spc3 and delta < max_observation and\n",
    "                                row['Vehicle Location'] == 'Space 3'):\n",
    "        return 'Violator' + suffix\n",
    "    elif row['Vehicle Location'] == 'SB bike lane':\n",
    "        return 'Bike Lane Blocking' + suffix\n",
    "    else:\n",
    "        return 'Likely Non-Violator' + suffix\n",
    "    \n",
    "def classify_violators(df):\n",
    "    #add boolean violator column to original (pre-timestamp) df. Also zeropads dates.\n",
    "    df.dropna(subset=['Begin Time', 'End Time'], inplace=True)\n",
    "    #added unique id to each activity\n",
    "    df = df.reset_index().rename(columns={'index':'Activity Id'})\n",
    "    df['Begin Date'] = df['Begin Date'].apply(zeropad_dates)\n",
    "    df['Violator'] = df.apply(classify_violator, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "cimport numpy\n",
    "\n",
    "def datetime_from_str(string):\n",
    "    \"\"\"converts string format dates/times from spreadsheet\n",
    "    into Python Datetime objects\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #print('ran, string:{}'.format(string))\n",
    "        format_str = '%m/%d/%Y%I:%M:%S %p'\n",
    "        to_dt = dt.datetime.strptime(string, format_str)\n",
    "    except ValueError:\n",
    "        #handles small portion of values in 24hr format\n",
    "        try:\n",
    "            #print('excepted, string:{}'.format(string))\n",
    "            format_str = '%m/%d/%Y%H:%M:%S'\n",
    "            to_dt = dt.datetime.strptime(string, format_str)\n",
    "        \n",
    "        except ValueError:\n",
    "            #use dict to handle both text-described times\n",
    "            text_times_dict = {'before 12':'12:00:00', 'end of the day':'22:30:00'}\n",
    "            #print('excepted2, string:{}'.format(string))\n",
    "            texttime = string[10:]\n",
    "            time = text_times_dict[texttime]\n",
    "            combined = string[:10] + time\n",
    "            return datetime_from_str(combined)\n",
    "    return to_dt\n",
    "\n",
    "def cy_timestamps_from_interval(dt_start, dt_end):\n",
    "    \"\"\"creates range of np.datetime64 for every second in interval\"\"\"\n",
    "    dt64_st = np.datetime64(dt_start)\n",
    "    #add one second to include end value in range\n",
    "    dt64_end = np.datetime64(dt_end) + np.timedelta64(1, 's')\n",
    "    return np.arange(dt64_st, dt64_end, dtype='datetime64[s]')\n",
    "\n",
    "def timestamps_from_row(row):\n",
    "    \"\"\"extracts interval from a row of the original spreadsheet\"\"\"\n",
    "    start = row[1]['Begin Date'] + row[1]['Begin Time'] \n",
    "    end = row[1]['Begin Date'] + row[1]['End Time'] \n",
    "    \n",
    "    dt_start = datetime_from_str(start)\n",
    "    dt_end = datetime_from_str(end)\n",
    "    \n",
    "    return cy_timestamps_from_interval(dt_start, dt_end)\n",
    "\n",
    "def index_for_row(row):\n",
    "    \"\"\"creates pd.DateTimeIndex for a single row of the original spreadsheet\"\"\"\n",
    "    timestamps = timestamps_from_row(row)\n",
    "    return pd.Index(timestamps, name='Timestamp')\n",
    "    \n",
    "def df_for_row(row):\n",
    "    \"\"\"generates timestamped dataframe from a \n",
    "    single row of the violator-classified dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ind = index_for_row(row)\n",
    "        row_df = pd.DataFrame(row[1]).swapaxes('index', 'columns')\n",
    "        row_df = pd.concat([row_df]*len(ind))\n",
    "        row_df.index = ind\n",
    "    except ValueError:\n",
    "        display(row_df)\n",
    "        print(ind)\n",
    "        return\n",
    "    return row_df\n",
    "\n",
    "def cy_timestamp_df(df):\n",
    "    \"\"\"Generates timestamped dataframe from violator-classified dataframe.\"\"\"\n",
    "    i = 0\n",
    "    df_list = []\n",
    "    timestamped_df = pd.DataFrame()\n",
    "    for row in df.iterrows():\n",
    "        if i % 100 == 0:\n",
    "            #TODO rewrite to include %complete, ETA?\n",
    "            print('Processing Row: {}, {}% complete'.format(i, int((i/df.shape[0])*100)))\n",
    "        i += 1\n",
    "        df_list += [df_for_row(row)]\n",
    "        \n",
    "    timestamped_df = timestamped_df.append(df_list)\n",
    "    return timestamped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_and_classify_violators(df):\n",
    "    \"\"\"simple wrapper to classify biolators then timestamp\"\"\"\n",
    "    return cy_timestamp_df(classify_violators(df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_viol_time(df, hour=22, opr='=='):\n",
    "    \"\"\"switches Violator to Likely Non-Violator\n",
    "    for rows in specified range of timestamped dataframe\n",
    "    \"\"\"\n",
    "##TODO reduce redunancy? \n",
    "##TODO also, currently doesn't handle TNC/CNS violators. \n",
    "##Not a huge deal since they rarely span interval, but may want to fix\n",
    "    ops = {'>': operator.gt,\n",
    "           '<': operator.lt,\n",
    "           '>=': operator.ge,\n",
    "           '<=': operator.le,\n",
    "           '==': operator.eq}\n",
    "\n",
    "    df.sort_index(level='Timestamp', inplace=True)\n",
    "    times = df.index.get_level_values(level='Timestamp')\n",
    "    hr = ops[opr](times.hour, hour)\n",
    "    filtered = df.loc[hr]\n",
    "    filtered.loc[:, 'Violator'] = filtered.loc[:, 'Violator'].apply(lambda x: 'Likely Non-Violator' if x == 'Violator' else x)\n",
    "    df = df.loc[~hr]\n",
    "    df = df.append(filtered)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Row: 0, 0% complete\n",
      "Processing Row: 100, 4% complete\n",
      "Processing Row: 200, 8% complete\n",
      "Processing Row: 300, 13% complete\n",
      "Processing Row: 400, 17% complete\n",
      "Processing Row: 500, 22% complete\n",
      "Processing Row: 600, 26% complete\n",
      "Processing Row: 700, 31% complete\n",
      "Processing Row: 800, 35% complete\n",
      "Processing Row: 900, 39% complete\n",
      "Processing Row: 1000, 44% complete\n",
      "Processing Row: 1100, 48% complete\n",
      "Processing Row: 1200, 53% complete\n",
      "Processing Row: 1300, 57% complete\n",
      "Processing Row: 1400, 62% complete\n",
      "Processing Row: 1500, 66% complete\n",
      "Processing Row: 1600, 70% complete\n",
      "Processing Row: 1700, 75% complete\n",
      "Processing Row: 1800, 79% complete\n",
      "Processing Row: 1900, 84% complete\n",
      "Processing Row: 2000, 88% complete\n",
      "Processing Row: 2100, 93% complete\n",
      "Processing Row: 2200, 97% complete\n"
     ]
    }
   ],
   "source": [
    "alldays_timestamped = timestamp_and_classify_violators(alldays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldays_timestamped = reset_viol_time(alldays_timestamped)\n",
    "# alldays_timestamped = reset_viol_time(alldays_timestamped, hour=18, opr='<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1595953, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldays_timestamped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581475, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldays_timestamped.dropna(subset=['Duration']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO ensure sort happens in timestamper...\n",
    "alldays_timestamped = alldays_timestamped.dropna(subset=['Duration'])\n",
    "alldays_timestamped.sort_index(level='Timestamp', inplace=True)\n",
    "alldays_timestamped.to_parquet('TimestampToSep11new.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
